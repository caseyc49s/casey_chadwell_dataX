{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2019: Homework 7\n",
    "\n",
    "### Webscraping\n",
    "\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with web-scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Casey Chadwell\n",
    "\n",
    "## SID: 3033291861\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun with Webscraping & Text manipulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Statistics in Presidential Debates\n",
    "\n",
    "Your first task is to scrape Presidential Debates from the Commission of Presidential Debates website: https://www.debates.org/voter-education/debate-transcripts/\n",
    "\n",
    "To do this, you are not allowed to manually look up the URLs that you need, instead you have to scrape them. The root url to be scraped is the one listed above, namely: https://www.debates.org/voter-education/debate-transcripts/\n",
    "\n",
    "\n",
    "1. By using `requests` and `BeautifulSoup` find all the links / URLs on the website that links to transcriptions of **First Presidential Debates** from the years [1988, 1984, 1976, 1960]. In total you should find 4 links / URLs that fulfill this criteria. **Print the urls.**\n",
    "\n",
    "2. When you have a list of the URLs your task is to create a Data Frame with some statistics (see example of output below):\n",
    "    1. Scrape the title of each link and use that as the column name in your Data Frame. \n",
    "    2. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include `\\` characters in your count, but remove any breakline characters, i.e. `\\n`. You will get credit if your count is +/- 10% from our result.\n",
    "    3. Count how many times the word **war** was used in the different debates. Note that you have to convert the text in a smart way (to not count the word **warranty** for example, but counting **war.**, **war!**, **war,** or **War** etc.\n",
    "    4. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in C in order to do this.\n",
    "    \n",
    "    **Print your final output result.**\n",
    "    \n",
    "**Tips:**\n",
    "\n",
    "___\n",
    "\n",
    "In order to solve the questions above, it can be useful to work with Regular Expressions and explore methods on strings like `.strip(), .replace(), .find(), .count(), .lower()` etc. Both are very powerful tools to do string processing in Python. To count common words for example I used a `Counter` object and a Regular expression pattern for only words, see example:\n",
    "\n",
    "```python\n",
    "    from collections import Counter\n",
    "    import re\n",
    "\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "```\n",
    "\n",
    "Read more about Regular Expressions here: https://docs.python.org/3/howto/regex.html\n",
    "    \n",
    "    \n",
    "**Example output of all of the answers to Question 1.2:**\n",
    "\n",
    "\n",
    "![pres_stats_2](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/presidents_stats_2.jpg)\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4 as bs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Links to First Presidential Debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988 : https://www.debates.org/voter-education/debate-transcripts/september-25-1988-debate-transcript/\n",
      "1984 : https://www.debates.org/voter-education/debate-transcripts/october-7-1984-debate-transcript/\n",
      "1976 : https://www.debates.org/voter-education/debate-transcripts/september-23-1976-debate-transcript/\n",
      "1960 : https://www.debates.org/voter-education/debate-transcripts/september-26-1960-debate-transcript/\n"
     ]
    }
   ],
   "source": [
    "source = requests.get(\"https://www.debates.org/voter-education/debate-transcripts/\") \n",
    "soup = bs.BeautifulSoup(source.content, features='html.parser') \n",
    "all_a = soup.find_all('a')\n",
    "\n",
    "links_to_years = []\n",
    "titles = []\n",
    "\n",
    "for a in all_a:\n",
    "    if re.search(r'(1988|1984|1976|1960): The First', a.contents[0]):\n",
    "        link = a.get('href')\n",
    "        links_to_years.append(link)\n",
    "        titles.append(a.contents[0])\n",
    "        \n",
    "for link in links_to_years:\n",
    "    print(re.findall(r'(1988|1984|1976|1960)', link)[0], ': https://www.debates.org' + link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Data Frame and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. titles as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['September 25, 1988: The First Bush-Dukakis Presidential Debate',\n",
       " 'October 7, 1984: The First Reagan-Mondale Presidential Debate',\n",
       " 'September 23, 1976: The First Carter-Ford Presidential Debate',\n",
       " 'September 26, 1960: The First Kennedy-Nixon Presidential Debate']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got titles above in for loop\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include \\ characters in your count, but remove any breakline characters, i.e. \\n. You will get credit if your count is +/- 10% from our result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87488, 86505, 80735, 60937]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_char_count(url, div_id):\n",
    "    source = requests.get(url)\n",
    "    soup = bs.BeautifulSoup(source.content, features='html.parser')\n",
    "    all_divs = soup.find(id = div_id).text\n",
    "    return(len(str(all_divs).replace('\\n', '')))\n",
    "\n",
    "counts = []\n",
    "\n",
    "for link in links_to_years:\n",
    "    counts.append(get_char_count('https://www.debates.org' + link, 'content-sm'))\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Count how many times the word war was used in the different debates. Note that you have to convert the text in a smart way (to not count the word warranty for example, but counting war., war!, war, or War etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 5, 3]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_war_count(url, div_id):\n",
    "    source = requests.get(url)\n",
    "    soup = bs.BeautifulSoup(source.content, features='html.parser')\n",
    "    all_divs = soup.find(id = div_id).text\n",
    "    return(len(re.findall(' war ', re.sub(r\"[^\\w\\s]+?\", \"\", str(all_divs).lower()))))\n",
    "\n",
    "war_counts = []\n",
    "\n",
    "for link in links_to_years:\n",
    "    war_counts.append(get_war_count('https://www.debates.org' + link, 'content-sm'))\n",
    "\n",
    "war_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in C in order to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'the', 'the']\n",
      "[799, 867, 856, 779]\n"
     ]
    }
   ],
   "source": [
    "def get_common_count(url, div_id):\n",
    "    source = requests.get(url)\n",
    "    soup = bs.BeautifulSoup(source.content, features='html.parser')\n",
    "    all_divs = soup.find(id = div_id).text\n",
    "    words = re.findall('\\w+', re.sub(r\"[^\\w\\s]+?\", \"\", str(all_divs).lower()))\n",
    "    Counter(words).most_common(10)\n",
    "    return(Counter(words).most_common(1))\n",
    "    \n",
    "\n",
    "common_w = []\n",
    "common_c = []\n",
    "\n",
    "for link in links_to_years:\n",
    "    common = get_common_count('https://www.debates.org' + link, 'content-sm')\n",
    "    common_w.append(common[0][0])\n",
    "    common_c.append(common[0][1])\n",
    "\n",
    "print(common_w)\n",
    "print(common_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 End Solution: Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>September 25, 1988: The First Bush-Dukakis Presidential Debate</th>\n",
       "      <th>October 7, 1984: The First Reagan-Mondale Presidential Debate</th>\n",
       "      <th>September 23, 1976: The First Carter-Ford Presidential Debate</th>\n",
       "      <th>September 26, 1960: The First Kennedy-Nixon Presidential Debate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Debate char length</th>\n",
       "      <td>87488</td>\n",
       "      <td>86505</td>\n",
       "      <td>80735</td>\n",
       "      <td>60937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war_count</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w_count</th>\n",
       "      <td>799</td>\n",
       "      <td>867</td>\n",
       "      <td>856</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    September 25, 1988: The First Bush-Dukakis Presidential Debate  \\\n",
       "Debate char length                                               87488               \n",
       "war_count                                                            7               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                799               \n",
       "\n",
       "                    October 7, 1984: The First Reagan-Mondale Presidential Debate  \\\n",
       "Debate char length                                               86505              \n",
       "war_count                                                            2              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                867              \n",
       "\n",
       "                    September 23, 1976: The First Carter-Ford Presidential Debate  \\\n",
       "Debate char length                                               80735              \n",
       "war_count                                                            5              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                856              \n",
       "\n",
       "                    September 26, 1960: The First Kennedy-Nixon Presidential Debate  \n",
       "Debate char length                                               60937               \n",
       "war_count                                                            3               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                779               "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = [counts, war_counts, common_w, common_c], columns = titles, index = ['Debate char length', 'war_count', 'most_common_w', 'most_common_w_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2. Download and read in specific line from many data sets\n",
    "\n",
    "Scrape the first 27 data sets from this URL http://people.sc.fsu.edu/~jburkardt/datasets/regression/ (i.e.`x01.txt` - `x27.txt`). Then, save the 5th line in each data set, this should be the name of the data set author (get rid of the `#` symbol, the white spaces and the comma at the end). \n",
    "\n",
    "Count how many times (with a Python function) each author is the reference for one of the 27 data sets. Showcase your results, sorted, with the most common author name first and how many times he appeared in data sets. Use a Pandas DataFrame to show your results, see example. **Print your final output result.**\n",
    "\n",
    "**Example output of the answer for Question 2:**\n",
    "\n",
    "![author_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/data_authors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?C=N;O=D\n",
      "?C=M;O=A\n",
      "?C=S;O=A\n",
      "?C=D;O=A\n",
      "/~jburkardt/datasets/\n",
      "regression.html\n",
      "x01.txt\n",
      "x02.txt\n",
      "x03.txt\n",
      "x04.txt\n",
      "x05.txt\n",
      "x06.txt\n",
      "x07.txt\n",
      "x08.txt\n",
      "x09.txt\n",
      "x10.txt\n",
      "x11.txt\n",
      "x12.txt\n",
      "x13.txt\n",
      "x14.txt\n",
      "x15.txt\n",
      "x16.txt\n",
      "x17.txt\n",
      "x18.txt\n",
      "x19.txt\n",
      "x20.txt\n",
      "x21.txt\n",
      "x22.txt\n",
      "x23.txt\n",
      "x24.txt\n",
      "x25.txt\n",
      "x26.txt\n",
      "x27.txt\n",
      "x28.txt\n",
      "x29.txt\n",
      "x30.txt\n",
      "x31.txt\n",
      "x32.txt\n",
      "x33.txt\n",
      "x34.txt\n",
      "x35.txt\n",
      "x36.txt\n",
      "x37.txt\n",
      "x38.txt\n",
      "x39.txt\n",
      "x40.txt\n",
      "x41.txt\n",
      "x42.txt\n",
      "x43.txt\n",
      "x43_01.txt\n",
      "x43_02.txt\n",
      "x43_03.txt\n",
      "x44.txt\n",
      "x44_01.txt\n",
      "x44_02.txt\n",
      "x44_03.txt\n",
      "x45.txt\n",
      "x45_01.txt\n",
      "x45_02.txt\n",
      "x45_03.txt\n",
      "x46.txt\n",
      "x47.txt\n",
      "x47_01.txt\n",
      "x47_02.txt\n",
      "x47_03.txt\n",
      "x48.txt\n",
      "x48_01.txt\n",
      "x48_02.txt\n",
      "x48_03.txt\n",
      "x49.txt\n",
      "x49_01.txt\n",
      "x49_02.txt\n",
      "x49_03.txt\n",
      "x50.txt\n",
      "x50_01.txt\n",
      "x50_02.txt\n",
      "x50_03.txt\n",
      "x51.txt\n",
      "x51_01.txt\n",
      "x51_02.txt\n",
      "x51_03.txt\n",
      "x52.txt\n",
      "x52_01.txt\n",
      "x52_02.txt\n",
      "x52_03.txt\n",
      "x53.txt\n",
      "x53_01.txt\n",
      "x53_02.txt\n",
      "x53_03.txt\n",
      "x54.txt\n",
      "x54_01.txt\n",
      "x54_02.txt\n",
      "x54_03.txt\n",
      "x55.txt\n",
      "x55_01.txt\n",
      "x55_02.txt\n",
      "x55_03.txt\n",
      "x56.txt\n",
      "x56_01.txt\n",
      "x56_02.txt\n",
      "x56_03.txt\n",
      "x57.txt\n",
      "x57_01.txt\n",
      "x57_02.txt\n",
      "x57_03.txt\n",
      "x58.txt\n",
      "x58_01.txt\n",
      "x58_03.txt\n",
      "x59.txt\n",
      "x59_01.txt\n",
      "x59_02.txt\n",
      "x59_03.txt\n",
      "x60.txt\n",
      "x61.txt\n",
      "x61_01.txt\n",
      "x61_02.txt\n",
      "x61_03.txt\n",
      "x62.txt\n",
      "['Name', 'Last modified', 'Size', 'Description', 'Parent Directory', 'regression.html', 'x01.txt', 'x02.txt', 'x03.txt', 'x04.txt', 'x05.txt', 'x06.txt', 'x07.txt', 'x08.txt', 'x09.txt', 'x10.txt', 'x11.txt', 'x12.txt', 'x13.txt', 'x14.txt', 'x15.txt', 'x16.txt', 'x17.txt', 'x18.txt', 'x19.txt', 'x20.txt', 'x21.txt', 'x22.txt', 'x23.txt', 'x24.txt', 'x25.txt', 'x26.txt', 'x27.txt', 'x28.txt', 'x29.txt', 'x30.txt', 'x31.txt', 'x32.txt', 'x33.txt', 'x34.txt', 'x35.txt', 'x36.txt', 'x37.txt', 'x38.txt', 'x39.txt', 'x40.txt', 'x41.txt', 'x42.txt', 'x43.txt', 'x43_01.txt', 'x43_02.txt', 'x43_03.txt', 'x44.txt', 'x44_01.txt', 'x44_02.txt', 'x44_03.txt', 'x45.txt', 'x45_01.txt', 'x45_02.txt', 'x45_03.txt', 'x46.txt', 'x47.txt', 'x47_01.txt', 'x47_02.txt', 'x47_03.txt', 'x48.txt', 'x48_01.txt', 'x48_02.txt', 'x48_03.txt', 'x49.txt', 'x49_01.txt', 'x49_02.txt', 'x49_03.txt', 'x50.txt', 'x50_01.txt', 'x50_02.txt', 'x50_03.txt', 'x51.txt', 'x51_01.txt', 'x51_02.txt', 'x51_03.txt', 'x52.txt', 'x52_01.txt', 'x52_02.txt', 'x52_03.txt', 'x53.txt', 'x53_01.txt', 'x53_02.txt', 'x53_03.txt', 'x54.txt', 'x54_01.txt', 'x54_02.txt', 'x54_03.txt', 'x55.txt', 'x55_01.txt', 'x55_02.txt', 'x55_03.txt', 'x56.txt', 'x56_01.txt', 'x56_02.txt', 'x56_03.txt', 'x57.txt', 'x57_01.txt', 'x57_02.txt', 'x57_03.txt', 'x58.txt', 'x58_01.txt', 'x58_03.txt', 'x59.txt', 'x59_01.txt', 'x59_02.txt', 'x59_03.txt', 'x60.txt', 'x61.txt', 'x61_01.txt', 'x61_02.txt', 'x61_03.txt', 'x62.txt']\n"
     ]
    }
   ],
   "source": [
    "base_link = \"http://people.sc.fsu.edu/~jburkardt/datasets/regression/\"\n",
    "source = requests.get(base_link) \n",
    "soup = bs.BeautifulSoup(source.content, features='html.parser') \n",
    "all_a = soup.find_all('a')\n",
    "\n",
    "links_to_years = []\n",
    "titles = []\n",
    "\n",
    "for a in all_a:\n",
    "    if re.search('(x([0-1][0-9]|.txt)|(x2[0-7].txt)', a.contents[0]):\n",
    "        lines = []\n",
    "        link = a.get('href')\n",
    "        with open (base_link + link, 'rt') as cur_file:  # Open file lorem.txt for reading of text data.\n",
    "        for line in in_file: # Store each line in a string variable \"line\"\n",
    "            \n",
    "        \n",
    "with open ('lorem.txt', 'rt') as in_file:  #Open file lorem.txt for reading of text data.\n",
    "for line in in_file: #For each line of text store in a string variable named \"line\", and\n",
    "lines.append(line)  #add that line to our list of lines.\n",
    "print(lines)        #print the list object.\n",
    "        re.\n",
    "        links_to_years.append(link)\n",
    "        titles.append(a.contents[0])\n",
    "with open ('lorem.txt', 'rt') as in_file:  # Open file lorem.txt for reading of text data.\n",
    "for line in in_file: # Store each line in a string variable \"line\"\n",
    "print(line) # prints that line\n",
    "    \n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
